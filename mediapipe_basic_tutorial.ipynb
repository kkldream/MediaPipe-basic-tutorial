{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mediapipe_basic_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "eebqK7dnZv_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAITXK5WZXh7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_1.jpg')\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "sWjhil6PoBz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Face Detection"
      ],
      "metadata": {
        "id": "TVOkkq_H8VWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化面部檢測模型\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
        "mp_drawing = mp.solutions.drawing_utils"
      ],
      "metadata": {
        "id": "QDU6_DKOd_yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 官方範例程式"
      ],
      "metadata": {
        "id": "Lh9L0gSVnuue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_1.jpg')\n",
        "# 將BGR圖像轉換為RGB，並使用MediaPipe面部檢測進行處理\n",
        "results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.detections:\n",
        "  for detection in results.detections:\n",
        "    \n",
        "    # 印出檢測結果\n",
        "    print(detection)\n",
        "\n",
        "    # 使用官方API函式繪製檢測結果\n",
        "    mp_drawing.draw_detection(image, detection)\n",
        "\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "uzY75nred_r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 眼睛黑線遮蔽"
      ],
      "metadata": {
        "id": "hcVFZgkFn08h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_1.jpg')\n",
        "results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.detections:\n",
        "  for detection in results.detections:\n",
        "    \n",
        "    # 方法1: 使用官方API函式獲取標點位置\n",
        "    left_eye_tip = mp_face_detection.get_key_point(detection, mp_face_detection.FaceKeyPoint.LEFT_EYE)\n",
        "    right_eye_tip = mp_face_detection.get_key_point(detection, mp_face_detection.FaceKeyPoint.RIGHT_EYE)\n",
        "    \n",
        "    # 使用2: 使用物件導向的方式獲取標點位置\n",
        "    # left_eye_tip = detection.location_data.relative_keypoints[0]\n",
        "    # right_eye_tip = detection.location_data.relative_keypoints[1]\n",
        "    \n",
        "    # 計算標點的像素座標\n",
        "    left_eye_pos = (int(image.shape[1] * left_eye_tip.x), int(image.shape[0] * left_eye_tip.y))\n",
        "    right_eye_pos = (int(image.shape[1] * right_eye_tip.x), int(image.shape[0] * right_eye_tip.y))\n",
        "\n",
        "    # 畫線\n",
        "    cv2.line(image, left_eye_pos, right_eye_pos, (0,0,0), 30)\n",
        "\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "0hpV8g9TnqCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 臉部馬賽克效果"
      ],
      "metadata": {
        "id": "IODGmxYun8FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 馬賽克函式\n",
        "def mosaic_effect(img, bbox, size=10):\n",
        "  x, y, w, h = bbox\n",
        "  new_img = img.copy()\n",
        "  for m in range(y, y+h):\n",
        "    for n in range(x, x+w):\n",
        "      if m % size == 0 and n % size == 0:\n",
        "        for i in range(0, size):\n",
        "          for j in range(0, size):\n",
        "            (b, g, r) = new_img[m, n]\n",
        "            new_img[i + m, j + n] = (b, g, r)\n",
        "  return new_img"
      ],
      "metadata": {
        "id": "LqsSfD0-j4Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_1.jpg')\n",
        "results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.detections:\n",
        "  for detection in results.detections:\n",
        "    bbox_tip = detection.location_data.relative_bounding_box\n",
        "    bbox_pos = [\n",
        "      int(image.shape[1] * bbox_tip.xmin),\n",
        "      int(image.shape[0] * bbox_tip.ymin),\n",
        "      int(image.shape[1] * bbox_tip.width),\n",
        "      int(image.shape[0] * bbox_tip.height)\n",
        "    ]\n",
        "    image = mosaic_effect(image, bbox_pos)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "5XFJkzOdezxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Mesh"
      ],
      "metadata": {
        "id": "G-OmPoV78OSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_2.jpg')\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "YPoUg1aLCsPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化面部標記模型\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "  static_image_mode=True,\n",
        "  max_num_faces=1,\n",
        "  refine_landmarks=True,\n",
        "  min_detection_confidence=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "X9n55I0W9X0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 官方範例程式"
      ],
      "metadata": {
        "id": "RHZopd26I1lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_2.jpg')\n",
        "results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.multi_face_landmarks:\n",
        "  for face_landmarks in results.multi_face_landmarks:\n",
        "\n",
        "    # 印出檢測結果\n",
        "    print(face_landmarks)\n",
        "\n",
        "    # 使用官方API函式繪製檢測結果\n",
        "    mp_drawing.draw_landmarks(\n",
        "        image=image,\n",
        "        landmark_list=face_landmarks,\n",
        "        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "        landmark_drawing_spec=None,\n",
        "        connection_drawing_spec=mp_drawing_styles\n",
        "        .get_default_face_mesh_tesselation_style())\n",
        "    mp_drawing.draw_landmarks(\n",
        "        image=image,\n",
        "        landmark_list=face_landmarks,\n",
        "        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "        landmark_drawing_spec=None,\n",
        "        connection_drawing_spec=mp_drawing_styles\n",
        "        .get_default_face_mesh_contours_style())\n",
        "    mp_drawing.draw_landmarks(\n",
        "        image=image,\n",
        "        landmark_list=face_landmarks,\n",
        "        connections=mp_face_mesh.FACEMESH_IRISES,\n",
        "        landmark_drawing_spec=None,\n",
        "        connection_drawing_spec=mp_drawing_styles\n",
        "        .get_default_face_mesh_iris_connections_style())\n",
        "\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "ioTi1dJO8QgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 打哈欠偵測"
      ],
      "metadata": {
        "id": "CiwGoFKHI8B8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算兩點距離函式\n",
        "def calc_distance(point_0, point_1):\n",
        "  distance = math.pow((point_0[0] - point_1[0]), 2) + math.pow((point_0[1] - point_1[1]), 2)\n",
        "  distance = math.sqrt(distance)\n",
        "  return distance"
      ],
      "metadata": {
        "id": "eQ_WFQhc_e6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_2.jpg')\n",
        "results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.multi_face_landmarks:\n",
        "  for face_landmarks in results.multi_face_landmarks:\n",
        "    point = [\n",
        "      (int(image.shape[1] * face_landmarks.landmark[61].x), int(image.shape[0] * face_landmarks.landmark[61].y)),\n",
        "      (int(image.shape[1] * face_landmarks.landmark[81].x), int(image.shape[0] * face_landmarks.landmark[81].y)),\n",
        "      (int(image.shape[1] * face_landmarks.landmark[311].x), int(image.shape[0] * face_landmarks.landmark[311].y)),\n",
        "      (int(image.shape[1] * face_landmarks.landmark[291].x), int(image.shape[0] * face_landmarks.landmark[291].y)),\n",
        "      (int(image.shape[1] * face_landmarks.landmark[402].x), int(image.shape[0] * face_landmarks.landmark[402].y)),\n",
        "      (int(image.shape[1] * face_landmarks.landmark[178].x), int(image.shape[0] * face_landmarks.landmark[178].y)),\n",
        "    ]\n",
        "    for p in point:\n",
        "      cv2.circle(image, p, 2, (0, 0, 255), -1)\n",
        "    ear = (calc_distance(point[1], point[5]) + calc_distance(point[2], point[4])) / (2 * calc_distance(point[0], point[3]))\n",
        "    cv2.putText(image, f'ear={ear:4.2f}', point[0], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "    \n",
        "    # 判斷打哈欠則執行動作\n",
        "    if ear > 0.5:\n",
        "      pass\n",
        "\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "Poy7_9eS_WjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 標記深度顏色顯示"
      ],
      "metadata": {
        "id": "dK2pt-IGE1Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_2.jpg')\n",
        "results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.multi_face_landmarks:\n",
        "  for face_landmarks in results.multi_face_landmarks:\n",
        "    for face_landmark in face_landmarks.landmark:\n",
        "      pos = (int(image.shape[1] * face_landmark.x), int(image.shape[0] * face_landmark.y))\n",
        "      depth = face_landmark.z\n",
        "      if depth >= 0:\n",
        "        cv2.circle(image, pos, 2, (0, 0, int(255 * depth * 50)), -1)\n",
        "      else:\n",
        "        cv2.circle(image, pos, 2, (int(255 * depth * -1 * 50), 0, 0), -1)\n",
        "\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "I6agMPpsE4YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 人頭三軸選轉角度"
      ],
      "metadata": {
        "id": "JisZKx3ZIofD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_2.jpg')\n",
        "results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.multi_face_landmarks:\n",
        "  for face_landmarks in results.multi_face_landmarks:\n",
        "\n",
        "    # 整理計算需用到的標記座標\n",
        "    left_eye_left_corner = (int(image.shape[1] * face_landmarks.landmark[226].x), int(image.shape[0] * face_landmarks.landmark[226].y))\n",
        "    right_eye_right_corner = (int(image.shape[1] * face_landmarks.landmark[446].x), int(image.shape[0] * face_landmarks.landmark[446].y))\n",
        "    left_eye_left_corner_z = face_landmarks.landmark[226].z\n",
        "    right_eye_right_corner_z = face_landmarks.landmark[446].z\n",
        "    face_top_z = face_landmarks.landmark[10].z\n",
        "    between_mouth_nose_z = face_landmarks.landmark[164].z\n",
        "\n",
        "    # 計算3軸選轉角度\n",
        "    roll = math.atan((right_eye_right_corner[1] - left_eye_left_corner[1]) / (right_eye_right_corner[0] - left_eye_left_corner[0])) * 180 / math.pi\n",
        "    yaw = (right_eye_right_corner_z - left_eye_left_corner_z) * 100\n",
        "    pitch = (face_top_z - between_mouth_nose_z) * 100\n",
        "    \n",
        "    print(f'roll = {roll}')\n",
        "    print(f'yaw = {yaw}')\n",
        "    print(f'pitch = {pitch}')\n",
        "\n",
        "    print_pos = [226, 446, 10, 164]\n",
        "    for p in print_pos:\n",
        "      face_landmark = face_landmarks.landmark[p]\n",
        "      pos = (int(image.shape[1] * face_landmark.x), int(image.shape[0] * face_landmark.y))\n",
        "      cv2.circle(image, pos, 4, (0, 0, 255), -1)\n",
        "\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "tDi7m_LYGVJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands"
      ],
      "metadata": {
        "id": "7H8kylr-JCju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_3.jpg')\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "T8t8ub1ALc3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化手勢檢測模型\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(\n",
        "  static_image_mode=True,\n",
        "  max_num_hands=4,\n",
        "  min_detection_confidence=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "hXtWiB4VJ-tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 官方範例程式"
      ],
      "metadata": {
        "id": "K05QIrKgL7AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_3.jpg')\n",
        "results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "print('Handedness:', results.multi_handedness)\n",
        "if results.multi_hand_landmarks:\n",
        "  image_height, image_width, _ = image.shape\n",
        "  for hand_landmarks in results.multi_hand_landmarks:\n",
        "    print('hand_landmarks:', hand_landmarks)\n",
        "    print(\n",
        "        f'Index finger tip coordinates: (',\n",
        "        f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
        "        f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
        "    )\n",
        "    mp_drawing.draw_landmarks(\n",
        "        image,\n",
        "        hand_landmarks,\n",
        "        mp_hands.HAND_CONNECTIONS,\n",
        "        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "        mp_drawing_styles.get_default_hand_connections_style())\n",
        "  cv2_imshow(cv2.flip(image, 1))\n",
        "  # Draw hand world landmarks.\n",
        "  if results.multi_hand_world_landmarks:\n",
        "    for hand_world_landmarks in results.multi_hand_world_landmarks:\n",
        "      mp_drawing.plot_landmarks(\n",
        "        hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)"
      ],
      "metadata": {
        "id": "G197VTrbJGV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 手勢判斷"
      ],
      "metadata": {
        "id": "__tyohF7L_Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_2d_angle(v1,v2): # 求出v1,v2兩條向量的夾角\n",
        "    v1_x=v1[0]\n",
        "    v1_y=v1[1]\n",
        "    v2_x=v2[0]\n",
        "    v2_y=v2[1]\n",
        "    try:\n",
        "        angle_= math.degrees(math.acos((v1_x*v2_x+v1_y*v2_y)/(((v1_x**2+v1_y**2)**0.5)*((v2_x**2+v2_y**2)**0.5))))\n",
        "    except:\n",
        "        angle_ = 100000.\n",
        "    return angle_\n",
        "\n",
        "def hand_angle(hand_):\n",
        "    angle_list = []\n",
        "    #---------------------------- thumb 大拇指角度\n",
        "    angle_ = vector_2d_angle(\n",
        "        ((int(hand_[0][0])- int(hand_[2][0])),(int(hand_[0][1])-int(hand_[2][1]))),\n",
        "        ((int(hand_[3][0])- int(hand_[4][0])),(int(hand_[3][1])- int(hand_[4][1])))\n",
        "        )\n",
        "    angle_list.append(angle_)\n",
        "    #---------------------------- index 食指角度\n",
        "    angle_ = vector_2d_angle(\n",
        "        ((int(hand_[0][0])-int(hand_[6][0])),(int(hand_[0][1])- int(hand_[6][1]))),\n",
        "        ((int(hand_[7][0])- int(hand_[8][0])),(int(hand_[7][1])- int(hand_[8][1])))\n",
        "        )\n",
        "    angle_list.append(angle_)\n",
        "    #---------------------------- middle 中指角度\n",
        "    angle_ = vector_2d_angle(\n",
        "        ((int(hand_[0][0])- int(hand_[10][0])),(int(hand_[0][1])- int(hand_[10][1]))),\n",
        "        ((int(hand_[11][0])- int(hand_[12][0])),(int(hand_[11][1])- int(hand_[12][1])))\n",
        "        )\n",
        "    angle_list.append(angle_)\n",
        "    #---------------------------- ring 無名指角度\n",
        "    angle_ = vector_2d_angle(\n",
        "        ((int(hand_[0][0])- int(hand_[14][0])),(int(hand_[0][1])- int(hand_[14][1]))),\n",
        "        ((int(hand_[15][0])- int(hand_[16][0])),(int(hand_[15][1])- int(hand_[16][1])))\n",
        "        )\n",
        "    angle_list.append(angle_)\n",
        "    #---------------------------- pink 小拇指角度\n",
        "    angle_ = vector_2d_angle(\n",
        "        ((int(hand_[0][0])- int(hand_[18][0])),(int(hand_[0][1])- int(hand_[18][1]))),\n",
        "        ((int(hand_[19][0])- int(hand_[20][0])),(int(hand_[19][1])- int(hand_[20][1])))\n",
        "        )\n",
        "    angle_list.append(angle_)\n",
        "    return angle_list\n",
        "\n",
        "def get_hand_angle(image, hand_landmarks):\n",
        "  keypoint_pos = []\n",
        "  for i in range(21):\n",
        "    x = hand_landmarks.landmark[i].x * image.shape[1]\n",
        "    y = hand_landmarks.landmark[i].y * image.shape[0]\n",
        "    keypoint_pos.append((x,y))\n",
        "  angle_list = hand_angle(keypoint_pos)\n",
        "  return angle_list\n"
      ],
      "metadata": {
        "id": "VMExVenhMOWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('img_3.jpg')\n",
        "results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "if results.multi_hand_landmarks:\n",
        "  for hand_landmarks in results.multi_hand_landmarks:\n",
        "    \n",
        "    angle_list = get_hand_angle(image, hand_landmarks)\n",
        "    print(angle_list)\n",
        "\n",
        "    mp_drawing.draw_landmarks(\n",
        "      image,\n",
        "      hand_landmarks,\n",
        "      mp_hands.HAND_CONNECTIONS,\n",
        "      mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "      mp_drawing_styles.get_default_hand_connections_style())\n",
        "    \n",
        "    hand_pos = (int(image.shape[1] * hand_landmarks.landmark[0].x), int(image.shape[0] * hand_landmarks.landmark[0].y))\n",
        "    if angle_list[0] > 50 and angle_list[4] > 50 and angle_list[1] < 30 and angle_list[2] < 30 and angle_list[3] < 30:\n",
        "      cv2.putText(image, '3', hand_pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "    if angle_list[0] > 50 and angle_list[1] > 50 and angle_list[2] < 30 and angle_list[3] < 30 and angle_list[4] < 30:\n",
        "      cv2.putText(image, 'OK', hand_pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "e23jKIX4Mbec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pose (自行練習)"
      ],
      "metadata": {
        "id": "eZvTTZNDYZzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d0RbkuXWYZpH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}